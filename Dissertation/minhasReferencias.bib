@misc{Lfw,
title = {Labeled Faces in the Wild},
url = {http://vis-www.cs.umass.edu/lfw/},
urldate = {2020-08-26}
}
@misc{Dlib,
title = {Dlib C++ Library},
url = {http://dlib.net/},
urldate = {2020-08-26}
}
@inproceedings{Brunelli1992,
abstract = {Several different techniques have been proposed for computer recognition of human faces. This paper presents the first results of an ongoing project to compare several recognition strategies on a common database. A set of algorithms has been developed to assess the feasibility of recognition using a vector of geometrical features, such as nose width and length, mouth position and chin shape. The performance of a Nearest Neighbor classifier, with a suitably defined metric, is reported as a function of the number of classes to be discriminated (people to be recognized) and of the number of examples per class. Finally, performance of classification with rejection is investigated.},
author = {Brunelli, R. and Poggio, T.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/3-540-55426-2_90},
isbn = {9783540554264},
issn = {16113349},
title = {{Face recognition through geometrical features}},
year = {1992}
}
@inproceedings{Cendrillon2000,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {Cendrillon, Raphael and Lovell, Brian},
booktitle = {Visual Communications and Image Processing 2000},
doi = {10.1117/12.386642},
issn = {0277786X},
title = {{Real-time face recognition using eigenfaces}},
year = {2000}
}
@inproceedings{Cox1996,
abstract = {We consider the problem of feature-based face recognition in the setting where only a single example of each face is available for training. The mixture-distance technique we introduce achieves a recognition rate of 95% on a database of 685 people in which each face is represented by 30 measured distances. This is currently the best recorded recognition rate for a feature-based system applied to a database of this size. By comparison, nearest neighbor search using Euclidean distance yields 84%. In our work a novel distance function is constructed based on local second order statistics as estimated by modeling the training data as a mixture of normal densities. We report on the results from mixtures of several sizes. We demonstrate that a flat mixture of mixtures performs as well as the best model and therefore represents an effective solution to the model selection problem. A mixture perspective is also taken for individual Gaussians to choose between first order (variance) and second order (covariance) models. Here an approximation to flat combination is proposed and seen to perform well in practice. Our results demonstrate that even in the absence of multiple training examples for each class, it is sometimes possible to infer from a statistical model of training data, a significantly improved distance function for use in pattern recognition.},
author = {Cox, Ingemar J. and Ghosn, Joumana and Yianilos, Peter N.},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/cvpr.1996.517076},
issn = {10636919},
title = {{Feature-based face recognition using mixture-distance}},
year = {1996}
}
@article{Jebara1996,
abstract = {Automatic face recognition has been a diicult problem in the eeld of computer vision for many y ears. Robust face recognition requires the ability to recognize identity despite many variations in appearance the face can have in a scene. We propose preceding recognition with a hierarchical detection system capable of searching images for human faces eeciently and with invariance to position, deformation, illumination, scale, and 3D pose. The detection and localization of a face are used to perform 3D normalization to the face prior to 2D linear recognition. Biologically motivated, low-level attentional mechanisms are applied at multiple scales to identify possible face regions. The facial contour is then estimated by computing symmet-ric enclosure and is used to guide the search for feature points within the face. Symmetric blob detection, limb extraction and signature analysis are used to locate the eyes, mouth and nose of each individual. A database of 3D range data of human heads allows us to align a 3D model to the coordinates of the detected feature points in the input image. The intensity image's textural representation of the face is mapped onto the 3D range data, thereby segmenting the face from the image. The 3D model is then rotated into a frontal view to synthesize a frontal \mug-shot" of the individual. Lighting and shading variations are corrected by histogram mtting. Once fully normalized, the image is projected into a low-dimensional subspace via Karhunen-Loeve Decomposition to compress the data and to verify detection. The resulting low-dimensional vector description is matched against a database using simple distance measures to determine the face's identity as one of the pre-viously identiied training examples. Due to the computational eeciency of the hierarchical detection scheme and the initial step of applying simple attentional mechanisms, tracking faces from a video source could be achieved. ii ACKNOWLEDGEMENTS},
author = {Jebara, Tony S},
journal = {Department of Electrical Engineering},
title = {{3D POSE ESTIMATION AND NORMALIZATION FOR FACE RECOGNITION}},
year = {1996}
}
@article{Brunelli1993,
abstract = {Over the last 20 years, several different techniques have been proposed for computer recognition of human faces. The purpose of this paper is to compare two simple but general strategies on a common database (frontal images of faces of 47 people: 26 males and 21 females, four images per person). We have developed and implemented two new algorithms; the first one is based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second one is based on almost-grey-level template matching. The results obtained on the testing sets (about 90% correct recognition using geometrical features and perfect recognition using template matching) favor our implementation of the template-matching approach. {\textcopyright} 1993 IEEE},
author = {Brunelli, Roberto and Poggio, Tomaso},
doi = {10.1109/34.254061},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Classification,expansion,face recognition. Karhunen-Loeve,template matching},
title = {{Face Recognition: Features versus Templates}},
year = {1993}
}
@article{Jafri2009,
abstract = {: Face recognition presents a challenging problem in the field of image analysis and computer vision, and as such has received a great deal of attention over the last few years because of its many applications in various domains. Face recognition techniques can be broadly divided into three categories based on the face data acquisition methodology: methods that operate on intensity images; those that deal with video sequences; and those that require other sensory data such as 3D information or infra-red imagery. In this paper, an overview of some of the well-known methods in each of these categories is provided and some of the benefits and drawbacks of the schemes mentioned therein are examined. Furthermore, a discussion outlining the incentive for using face recognition, the applications of this technology, and some of the difficulties plaguing current systems with regard to this task has also been provided. This paper also mentions some of the most recent algorithms developed for this purpose and attempts to give an idea of the state of the art of face recognition technology.},
author = {Jafri, Rabia and Arabnia, Hamid R.},
doi = {10.3745/jips.2009.5.2.041},
issn = {1976-913X},
journal = {Journal of Information Processing Systems},
title = {{A Survey of Face Recognition Techniques}},
year = {2009}
}
@book{StanZ.Li2011,
abstract = {Although the history of computer-aided face recognition stretches back to the 1960s, automatic face recognition remains an unsolved problem and still offers a great challenge to computer-vision and pattern recognition researchers. This handbook is a comprehensive account of face recognition research and technology, written by a group of leading international researchers. Twelve chapters cover all the sub-areas and major components for designing operational face recognition systems. Background, modern techniques, recent results, and challenges and future directions are considered. The book is aimed at practitioners and professionals planning to work in face recognition or wanting to become familiar with the state-of- the-art technology. A comprehensive handbook, by leading research authorities, on the concepts, methods, and algorithms for automated face detection and recognition. Essential reference resource for researchers and professionals in biometric security, computer vision, and video image analysis.},
address = {New York},
author = {{Stan Z. Li}, Anil K. Jain},
edition = {Second Edi},
publisher = {Springer},
title = {{Handbook of Face Recognition}},
year = {2011}
}
@article{Fischler1973,
abstract = {The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of “goodness” of matching or detection. We offer a combined descriptive scheme and decision metric which is general, intuitively satisfying, and which has led to promising experimental results. We also present an algorithm which takes the above descriptions, together with a matrix representing the intensities of the actual photograph, and then finds the described object in the matrix. The algorithm uses a procedure similar to dynamic programming in order to cut down on the vast amount of computation otherwise necessary. One desirable feature of the approach is its generality. A new programming system does not need to be written for every new description; instead, one just specifies descriptions in terms of a certain set of primitives and parameters. There are many areas of application: scene analysis and description, map matching for navigation and guidance, optical tracking, stereo compilation, and image change detection. In fact, the ability to describe, match, and register scenes is basic for almost any image processing task. Copyright {\textcopyright} 1973 by The Institute of Electrical and Electronics Engineers, Inc.},
author = {Fischler, Martin A. and Elschlager, Robert A.},
doi = {10.1109/T-C.1973.223602},
issn = {00189340},
journal = {IEEE Transactions on Computers},
keywords = {Dynamic programming,heuristic optimization,picture description,picture matching,picture processing,representation},
title = {{The Representation and Matching of Pictorial Structures Representation}},
year = {1973}
}
@misc{Heller2019,
author = {Heller, Martin},
booktitle = {InfoWorld},
title = {{Melhores bibliotecas de Machine e Deep Learning}},
url = {https://cio.com.br/melhores-bibliotecas-de-machine-e-deep-learning/},
urldate = {2020-08-24},
year = {2019}
}
@inproceedings{Viola2001,
abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "Integral Image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
author = {Viola, Paul and Jones, Michael},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/cvpr.2001.990517},
issn = {10636919},
title = {{Rapid object detection using a boosted cascade of simple features}},
year = {2001}
}
@article{Zafeiriou2015,
abstract = {Abstract Face detection is one of the most studied topics in computer vision literature, not only because of the challenging nature of face as an object, but also due to the countless applications that require the application of face detection as a first step. During the past 15 years, tremendous progress has been made due to the availability of data in unconstrained capture conditions (so-called 'in-the-wild') through the Internet, the effort made by the community to develop publicly available benchmarks, as well as the progress in the development of robust computer vision algorithms. In this paper, we survey the recent advances in real-world face detection techniques, beginning with the seminal Viola-Jones face detector methodology. These techniques are roughly categorized into two general schemes: rigid templates, learned mainly via boosting based methods or by the application of deep neural networks, and deformable models that describe the face by its parts. Representative methods will be described in detail, along with a few additional successful methods that we briefly go through at the end. Finally, we survey the main databases used for the evaluation of face detection algorithms and recent benchmarking efforts, and discuss the future of face detection.},
author = {Zafeiriou, Stefanos and Zhang, Cha and Zhang, Zhengyou},
doi = {10.1016/j.cviu.2015.03.015},
issn = {1090235X},
journal = {Computer Vision and Image Understanding},
keywords = {Boosting,Deep neural networks,Deformable models,Face detection,Feature extraction},
title = {{A survey on face detection in the wild: Past, present and future}},
year = {2015}
}
@inproceedings{Chen2016,
abstract = {The recent rapid development of urbanization and Internet of things (IoT) encourages more and more research on Smart City in which computing devices are widely distributed and huge amount of dynamic real-time data are collected and processed. Although vast volume of dynamic data are available for extracting new living patterns and making urban plans, efficient data processing and instant decision making are still key issues, especially in emergency situations requesting quick response with low latency. Fog Computing, as the extension of Cloud Computing, enables the computing tasks accomplished directly at the edge of the network and is characterized as low latency and real time computing. However, it is non-trivial to coordinate highly heterogeneous Fog Computing nodes to function as a homogeneous platform. In this paper, taking urban traffic surveillance as a case study, a dynamic video stream processing scheme is proposed to meet the requirements of real-time information processing and decision making. Furthermore, we have explored the potential to enable multi-target tracking function using a simpler single target tracking algorithm. A prototype is built and the performance is evaluated. The experimental results show that our scheme is a promising solution for smart urban surveillance applications.},
author = {Chen, Ning and Chen, Yu and You, Yang and Ling, Haibin and Liang, Pengpeng and Zimmermann, Roger},
booktitle = {Proceedings - 2016 IEEE 2nd International Conference on Multimedia Big Data, BigMM 2016},
doi = {10.1109/BigMM.2016.53},
isbn = {9781509021789},
keywords = {Fog Computing,Real-time processing,Smart City,Speeding Traffic,Urban Surveillance},
title = {{Dynamic urban surveillance video stream processing using fog computing}},
year = {2016}
}
@book{,
abstract = {Although the history of computer-aided face recognition stretches back to the 1960s, automatic face recognition remains an unsolved problem and still offers a great challenge to computer-vision and pattern recognition researchers. This handbook is a comprehensive account of face recognition research and technology, written by a group of leading international researchers. Twelve chapters cover all the sub-areas and major components for designing operational face recognition systems. Background, modern techniques, recent results, and challenges and future directions are considered. The book is aimed at practitioners and professionals planning to work in face recognition or wanting to become familiar with the state-of- the-art technology. A comprehensive handbook, by leading research authorities, on the concepts, methods, and algorithms for automated face detection and recognition. Essential reference resource for researchers and professionals in biometric security, computer vision, and video image analysis.},
booktitle = {Handbook of Face Recognition},
doi = {10.1007/b138828},
title = {{Handbook of Face Recognition}},
year = {2005}
}
@book{Kanade1977,
abstract = {Pictures o f human faces are successfully analyzed by a computer program which extracts face-feature points, such as nose, mouth, eyes and so on. The program was tested with more than 800 photographs. Emphasis is put on the flexible picture analysis scheme with feedback which was first enployed in the picture analysis program with remarkable success. The program consists of a collection of rather simple subroutines, each of which works on the specific part of the picture, and elaborate combination of them with backup procedures makes the whole process flexible and adaptive. An experiment on face identification of 20 people was also conducted.},
author = {Kanade, Takeo},
booktitle = {Computer recognition of human faces},
doi = {10.1007/978-3-0348-5737-6},
title = {{Computer recognition of human faces}},
year = {1977}
}
@misc{OpenCV,
title = {{OpenCV}},
url = {https://opencv.org/},
urldate = {2020-08-25}
}

@misc{OpenCV-CascadeClassifier,
title = {{OpenCV-CascadeClassifier}},
url = {https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html},
urldate = {2022-09-15},
year = {2022},
note = "[Online; acessado em 15-09-2022]"
}

@misc{OpenCV-PreTrainedModels,
title = {{OpenCV-PreTrainedModels}},
url = {https://github.com/opencv/opencv/tree/master/data/haarcascades},
urldate = {2022-09-15},
year = {2022},
note = "[Online; acessado em 15-09-2022]"
}

@misc{Picamera,
title = {{Picamera}},
url = {https://picamera.readthedocs.io/},
urldate = {2022-10-23},
year = {2022},
note = "[Online; acessado em 23-10-2022]"
}

@misc{DataStudio,
title = {{DataStudio}},
url = {https://datastudio.google.com/},
urldate = {2022-11-20},
year = {2022},
note = "[Online; acessado em 20-11-2022]"
}


@misc{Brownlee2019,
author = {Brownlee, Jason},
title = {{What is Deep Learning?}},
url = {https://machinelearningmastery.com/what-is-deep-learning/},
urldate = {2020-08-24},
year = {2019}
}
@article{Valera2011,
abstract = {A new generation of advanced surveillance systems is being conceived as a collection of multisensor components such as video, audio, and mobile robots interacting in a cooperating manner to enhance situation awareness capabilities to assist surveillance personnel. The prominent issues that these systems face are the improvement of existing intelligent video surveillance systems, the inclusion of wireless networks, the use of low power sensors, the design architecture, the communication between different components, the fusion of data emerging from different type of sensors, the location of personnel (providers and consumers), and the scalability of the system. This paper focuses on the aspects pertaining to real-time distributed architecture and scalability. For example, to meet real-time requirements, these systems need to process data streams in concurrent environments, designed by taking into account scheduling and synchronization. This paper proposes a framework for the design of visual surveillance systems based on components derived from the principles of real-time networks/data-oriented requirements implementation scheme. It also proposes the implementation of these components using the well-known middleware technology common object request broker architecture. Results using this architecture for video surveillance are presented through an implemented prototype. {\textcopyright} 2011 IEEE.},
author = {Valera, Maria and Velastin, Sergio A. and Ellis, Anna and Ferryman, James},
doi = {10.1109/TCSVT.2011.2133850},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {CORBA,DORIS,design architecture,intelligent video surveillance systems,modular software architecture,real-time networks},
title = {{Communication mechanisms and middleware for distributed video surveillance}},
year = {2011}
}
@article{Hu2004,
abstract = {Visual surveillance in dynamic scenes, especially for humans and vehicles, is currently one of the most active research topics in computer vision. It has a wide spectrum of promising applications, including access control in special areas, human identification at a distance, crowd flux statistics and congestion analysis, detection of anomalous behaviors, and interactive surveillance using multiple cameras, etc. In general, the processing framework of visual surveillance in dynamic scenes includes the following stages: modeling of environments, detection of motion, classification of moving objects, tracking, understanding and description of behaviors, human identification, and fusion of data from multiple cameras. We review recent developments and general strategies of all these stages. Finally, we analyze possible research directions, e.g., occlusion handling, a combination of two- and three-dimensional tracking, a combination of motion analysis and biometrics, anomaly detection and behavior prediction, content-based retrieval of surveillance videos, behavior understanding and natural language description, fusion of information from multiple sensors, and remote surveillance. {\textcopyright} 2004 IEEE.},
author = {Hu, Weiming and Tan, Tieniu and Wang, Liang and Maybank, Steve},
doi = {10.1109/TSMCC.2004.829274},
issn = {10946977},
journal = {IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews},
title = {{A survey on visual surveillance of object motion and behaviors}},
year = {2004}
}
@inproceedings{Cenedese2014,
abstract = {'Smart City' is a powerful paradigm that applies the most advanced communication technologies to urban environments, with the final aim of enhancing the quality of life in cities and provide a wide set of value-added services to both citizens and administration. A fundamental step towards the practical realization of the Smart City concept consists in the development of a communication infrastructure capable of collecting data from a large variety of different devices in a mostly uniform and seamless manner, according to the Internet of Things (IoT) paradigm. While the scientific and commercial interest in IoT has been constantly growing in the last years, practical experimentation of IoT systems has just begun. In this paper, we present and discuss the Padova Smart City system, an experimental realization of an urban IoT system designed within the Smart City framework and deployed in the city of Padova, Italy. We describe the system architecture and discuss the fundamental technical choices at the base of the project. Then, we analyze the data collected by the system and show how simple data processing techniques can be used to gain insights on the functioning of the monitored system, public traffic lighting in our specific case, as well as other information concerning the urban environment.},
author = {Cenedese, Angelo and Zanella, Andrea and Vangelista, Lorenzo and Zorzi, Michele},
booktitle = {Proceeding of IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks 2014, WoWMoM 2014},
doi = {10.1109/WoWMoM.2014.6918931},
isbn = {9781479947867},
keywords = {6LoWPAN,CoAP,EXI,Network Architecture,Sensor System Integration,Service Functions and Management,Smart Cities,Test-bed and Trials},
title = {{Padova smart City: An urban Internet of Things experimentation}},
year = {2014}
}
@article{Neapolitan2018,
abstract = {Neural Networks and Deep Learning is a free online book. The book will teach you about: Neural networks, a beautiful biologically-inspired programming paradigm which enables a computer to learn from observational data Deep learning, a powerful set of techniques for learning in neural networks Neural networks and deep learning currently provide the best solutions to many problems in image recognition, speech recognition, and natural language processing. This book will teach you many of the core concepts behind neural networks and deep learning.},
author = {Neapolitan, Richard E.},
doi = {10.1201/b22400-15},
file = {:home/conrado/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neapolitan - 2018 - Neural Networks and Deep Learning.pdf:pdf},
journal = {Artificial Intelligence},
pages = {389--411},
title = {{Neural Networks and Deep Learning}},
year = {2018}
}
@misc{Olson2006,
author = {Olson, Thomas J.},
pages = {16},
title = {{AUTOMATIC VIDEO MONITORING SYSTEM WHICH SELECTIVELY SAVES INFORMATION}},
url = {https://patentimages.storage.googleapis.com/f0/7b/a2/58558376b25dca/US7023469.pdf},
year = {2006}
}
@inproceedings{He2016,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2016.90},
eprint = {1512.03385},
isbn = {9781467388504},
issn = {10636919},
title = {{Deep residual learning for image recognition}},
year = {2016}
}
@article{Porter2010,
abstract = {Wide-area motion imagery (WAMI) sensors are placed on helicopters, balloons, small aircraft, or unmanned aerial vehicles and are used to image small city-sized areas at approximately 0.5 m/pixel and about one or two frames/s. The geospatial-temporal data sets produced by these systems allow for the observation of many dynamic phenomena that were previously inaccessible in street-level video data, but the efficient exploitation of this data poses significant technical challenges for image and video analysis and for data mining. Content of interest is defined in very abstract terms related to how humans interpret video imagery, but the data is defined in very physical terms related to the imaging device. This difference in representations is often called the semantic gap. In this review article, we describe advances that have been made and the advances that will be needed to produce the hierarchy of computational models required to narrow the semantic gap in WAMI. {\textcopyright} 2010 IEEE.},
author = {Porter, Reid and Fraser, Andrew M. and Hush, Don},
doi = {10.1109/MSP.2010.937396},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
title = {{Wide-area motion imagery}},
year = {2010}
}
@misc{BCB,
abstract = {Resultado da Corre{\c{c}}{\~{a}}o pelo IPCA (IBGE)},
author = {BCB},
title = {{Resultado da Corre{\c{c}}{\~{a}}o pelo IPCA (IBGE)}},
url = {https://www3.bcb.gov.br/CALCIDADAO/publico/corrigirPorIndice.do?method=corrigirPorIndice},
urldate = {2020-08-23}
}
@article{Tsakanikas2018,
abstract = {Within this survey an attempt is made to document the present status of video surveillance systems. The main components of a surveillance system are presented and studied thoroughly. Algorithms for image enhancement, object detection, object tracking, object recognition and item re-identification are presented. The most common modalities utilized by surveillance systems are discussed, putting emphasis on video, in terms of available resolutions and new imaging approaches, like High Dynamic Range video. The most important features and analytics are presented, along with the most common approaches for image / video quality enhancement. Distributed computational infrastructures are discussed (Cloud, Fog and Edge Computing), describing the advantages and disadvantages of each approach. The most important deep learning algorithms are presented, along with the smart analytics that they utilize. Augmented reality and the role it can play to a surveillance system is reported, just before discussing the challenges and the future trends of surveillance.},
author = {Tsakanikas, Vassilios and Dagiuklas, Tasos},
doi = {10.1016/j.compeleceng.2017.11.011},
issn = {00457906},
journal = {Computers and Electrical Engineering},
keywords = {Analytics,Cloud Computing,Computer vision,Edge Computing,Fog Computing,Image analysis,Image features,Surveillance,Surveillance analytics},
title = {{Video surveillance systems-current status and future trends}},
year = {2018}
}
@article{Anderson1999,
abstract = {This study estimates the total annual cost of criminal behavior in the United States. While past research has typically focused on particular costs, regions, or crime categories, this general study estimates all of the direct and indirect costs of crime for the entire nation. In addition to aggregating expenses commonly associated with unlawful activity, it considers ancillary costs that have not yet been included in an overall formula for the cost of crime. Beyond the expenses of the legal system, victim losses, and crime-prevention agencies, the burden of crime encompasses the opportunity costs of victims', criminals', and prisoners' time; the fear of being victimized; and the cost of private deterrence. More accurate information on the repercussions of crime could guide our legal, political, and cultural stance toward crime and allow informed prioritization of programs that curtail criminal activity. The net annual burden of crime is found to exceed $1 trillion.},
author = {Anderson, David A.},
doi = {10.1086/467436},
issn = {00222186},
journal = {Journal of Law and Economics},
title = {{The aggregate burden of crime}},
year = {1999}
}
@inproceedings{Nikouei2018,
abstract = {Edge computing efficiently extends the realm of information technology beyond the boundary defined by cloud computing paradigm. Performing computation near the source and destination, edge computing is promising to address the challenges in many delay-sensitive applications, like real-time human surveillance. Leveraging the ubiquitously connected cameras and smart mobile devices, it enables video analytics at the edge. In recent years, many smart video surveillance approaches are proposed for object detection and tracking by using Artificial Intelligence (AI) and Machine Learning (ML) algorithms. This work explores the feasibility of two popular human-objects detection schemes, Harr-Cascade and HOG feature extraction and SVM classifier, at the edge and introduces a lightweight Convolutional Neural Network (L-CNN) leveraging the depthwise separable convolution for less computation, for human detection. Single Board computers (SBC) are used as edge devices for tests and algorithms are validated using real-world campus surveillance video streams and open data sets. The experimental results are promising that the final algorithm is able to track humans with a decent accuracy at a resource consumption affordable by edge devices in real-time manner.},
archivePrefix = {arXiv},
arxivId = {1805.00331},
author = {Nikouei, Seyed Yahya and Chen, Yu and Song, Sejun and Xu, Ronghua and Choi, Baek Young and Faughnan, Timothy},
booktitle = {Proceedings - 4th IEEE International Conference on Collaboration and Internet Computing, CIC 2018},
doi = {10.1109/CIC.2018.00042},
eprint = {1805.00331},
isbn = {9781538695029},
keywords = {Edge Computing,Lightweight Convolutional Neural Network (L-CNN),Smart Surveillance},
title = {{Smart surveillance as an edge network service: From harr-cascade, SVM to a Lightweight CNN}},
year = {2018}
}
@article{Wilson1982,
abstract = {This deals with the throry that if a neighbourhood is run down then crime will increas as it it percieved that no one cares},
author = {Wilson, Jq and Kelling, Gl},
doi = {10.4135/9781412959193.n281},
isbn = {02769077},
issn = {0094-6575},
journal = {The Atlantic Monthly},
pmid = {16459745},
title = {{Broken Windows: the police and neighborhood safety}},
year = {1982}
}
@article{Puvvadi2015,
abstract = {Visual surveillance has numerous applications. It can support public safety, traffic monitoring, and facility protection to name just a few. Networked digital surveillance devices are revolutionizing the surveillance industry by supporting high quality images, remote monitoring, and advanced image processing. However, they also raise serious privacy/security concerns. To address the issue, the surveillance industry has recently begun to provide basic support for secure communications. In this paper, we present a new protocol to significantly enhance the security and performance compared with the state-of-the-art baseline method widely taken in the video surveillance industry. Through extensive experiments for performance evaluation, our approach is shown to substantially reduce the delay to execute cryptographic mechanisms and increase the supported bit rate compared with the baseline, while providing desirable security features.},
author = {Puvvadi, Udaya L.N. and {Di Benedetto}, Kevin and Patil, Aditya and Kang, Kyoung Don and Park, Youngjoon},
doi = {10.1109/TII.2015.2491259},
issn = {15513203},
journal = {IEEE Transactions on Industrial Informatics},
keywords = {Bit rate,Data confidentiality,Delay for cryptographic processing,Digital video surveillance,Freshness,Integrity},
title = {{Cost-effective security support in real-time video surveillance}},
year = {2015}
}
@article{Chen2019,
abstract = {In this paper, we propose a Distributed Intelligent Video Surveillance (DIVS) system using Deep Learning (DL) algorithms and deploy it in an edge computing environment. We establish a multi-layer edge computing architecture and a distributed DL training model for the DIVS system. The DIVS system can migrate computing workloads from the network center to network edges to reduce huge network communication overhead and provide low-latency and accurate video analysis solutions. We implement the proposed DIVS system and address the problems of parallel training, model synchronization, and workload balancing. Task-level parallel and model-level parallel training methods are proposed to further accelerate the video analysis process. In addition, we propose a model parameter updating method to achieve model synchronization of the global DL model in a distributed EC environment. Moreover, a dynamic data migration approach is proposed to address the imbalance of workload and computational power of edge nodes. Experimental results showed that the EC architecture can provide elastic and scalable computing power, and the proposed DIVS system can efficiently handle video surveillance and analysis tasks.},
archivePrefix = {arXiv},
arxivId = {1904.06400},
author = {Chen, Jianguo and Li, Kenli and Deng, Qingying and Li, Keqin and Yu, Philip S.},
doi = {10.1109/tii.2019.2909473},
eprint = {1904.06400},
issn = {1551-3203},
journal = {IEEE Transactions on Industrial Informatics},
title = {{Distributed Deep Learning Model for Intelligent Video Surveillance Systems with Edge Computing}},
year = {2019}
}
@misc{G12013,
abstract = {Relat{\'{o}}rio analisa impacto da viol{\^{e}}ncia em 18 pa{\'{i}}ses. Pesquisa aponta que crimes causaram perda de US$ 24 bilh{\~{o}}es.},
author = {G1},
booktitle = {O GLOBO},
title = {{Brasil tem a terceira maior taxa de roubos da Am{\'{e}}rica Latina, diz Pnud}},
year = {2013}
}
@inproceedings{Fernandes2007,
abstract = {Resumo Este artigo consiste em um m{\'{e}}todo para reconhecimento de faces baseado em Redes Neurais Artificiais que classificam tr{\^{e}}s caracter{\'{i}}sticas faciais e utiliza suas sa{\'{i}}das como entradas para a fus{\~{a}}o que {\'{e}} realizada pelo m{\'{e}}todo de vota{\c{c}}{\~{a}}o, este apresenta como sa{\'{i}}da o individuo reconhecido pelo sistema. Devido aos princ{\'{i}}pios b{\'{a}}sicos de redes neurais, o conjunto de dados foi dividido em conjunto de treinamento e valida{\c{c}}{\~{a}}o, como estes conjuntos apresentaram alta dimensionalidade, a t{\'{e}}cnica de PCA foi aplicada. Isto possibilitou um menor esfor{\c{c}}o computacional tanto na etapa de treinamento quanto na valida{\c{c}}{\~{a}}o e tamb{\'{e}}m melhores resultados puderam ser obtidos devido {\`{a}} extra{\c{c}}{\~{a}}o dos principais componentes. 1. Introdu{\c{c}}{\~{a}}o Com a sociedade necessitando cada vez mais de seguran{\c{c}}a, a busca pela cria{\c{c}}{\~{a}}o de sistemas inteligentes capazes de identificar indiv{\'{i}}duos de forma cada vez mais precisa em tarefas de dif{\'{i}}cil classifica{\c{c}}{\~{a}}o para seres humanos faz com que uma enorme variedade de metodologias para identifica{\c{c}}{\~{a}}o biom{\'{e}}trica [1, 2, 3, 4] seja pesquisada tais como: {\'{i}}ris, face, impress{\~{a}}o digital dentre outras. Este tipo de atividade requer muito esfor{\c{c}}o computacional, mas com o crescente avan{\c{c}}o da tecnologia estas tarefas passam a ser vi{\'{a}}veis e assim colocadas em pr{\'{a}}tica. Atualmente, pesquisadores procuram criar m{\'{e}}todos de reconhecimento multi-modais utilizando a jun{\c{c}}{\~{a}}o de v{\'{a}}rias caracter{\'{i}}sticas biom{\'{e}}tricas, por isto se faz necess{\'{a}}rio o aprimoramento no reconhecimento isolado de cada biometria, pois, o intuito {\'{e}} a cria{\c{c}}{\~{a}}o de sistemas com a melhor taxa de acertos poss{\'{i}}vel. Neste contexto, em [5] {\'{e}} proposto um reconhecimento de faces sobre tr{\^{e}}s caracter{\'{i}}sticas faciais aplicando-se PCA junto com um discriminante linear de Fisher para identificar cada caracter{\'{i}}stica facial e a seguir aplicar um m{\'{e}}todo de fus{\~{a}}o probabil{\'{i}}stica que fornece como resultado a pessoa reconhecida. A valida{\c{c}}{\~{a}}o do sistema acima citado utiliza as bases de dados de faces AR e FERET para mostrar que o reconhecimento de faces pelo m{\'{e}}todo de fus{\~{a}}o fornece melhor resposta quando comparado {\`{a}} classifica{\c{c}}{\~{a}}o de cada caracter{\'{i}}stica individual. Neste artigo prop{\^{o}}s-se a utiliza{\c{c}}{\~{a}}o de redes neurais artificiais nos processos de classifica{\c{c}}{\~{a}}o das caracter{\'{i}}sticas individuais e para fus{\~{a}}o um m{\'{e}}todo de vota{\c{c}}{\~{a}}o. As caracter{\'{i}}sticas faciais consideradas foram: imagem da face em tons de cinza, imagens com aplica{\c{c}}{\~{a}}o de filtros Butterworth (Passa-Baixa, Passa-Alta, Passa-Faixa), imagem com aplica{\c{c}}{\~{a}}o do filtro de Canny e uma imagem com aplica{\c{c}}{\~{a}}o dos filtros Derivativo e Gaussiano que {\'{e}} conhecida como Edginess. Cada caracter{\'{i}}stica facial utiliza sua pr{\'{o}}pria rede neural para reconhecimento individual. As taxas de acerto para cada caracter{\'{i}}stica foram analisadas e apenas as tr{\^{e}}s que contribu{\'{i}}am mais para o m{\'{e}}todo de fus{\~{a}}o foram utilizadas. Desta forma as caracter{\'{i}}sticas restantes foram eliminadas e a classifica{\c{c}}{\~{a}}o das tr{\^{e}}s caracter{\'{i}}sticas faciais feita novamente pelas redes neurais onde suas sa{\'{i}}das foram dadas como entradas para o m{\'{e}}todo de fus{\~{a}}o que fornece em sua sa{\'{i}}da o resultado do reconhecimento, isto {\'{e}}, o indiv{\'{i}}duo reconhecido. Para valida{\c{c}}{\~{a}}o do sistema a base de dados de faces AR foi utilizada. A partir dos resultados obtidos, as devidas conclus{\~{o}}es foram tomadas de acordo com a viabilidade de se utilizar classifica{\c{c}}{\~{a}}o de caracter{\'{i}}sticas faciais por redes neurais e com rela{\c{c}}{\~{a}}o {\`{a}} contribui{\c{c}}{\~{a}}o do m{\'{e}}todo de fus{\~{a}}o para melhoria do sistema.},
author = {Fernandes, R A S and Gonzaga, A},
booktitle = {Workshop de Vis{\~{a}}o Computacional},
title = {{Reconhecimento de Faces Utilizando Redes Neurais Artificiais com Fus{\~{a}}o de Caracter{\'{i}}sticas Faciais por M{\'{e}}todo de Vota{\c{c}}{\~{a}}o}},
year = {2007}
}
@inproceedings{Nikouei2018a,
abstract = {Edge computing allows more computing tasks to take place on the decentralized nodes at the edge of networks. Today many delay sensitive, mission-critical applications can leverage these edge devices to reduce the time delay or even to enable real-time, online decision making thanks to their onsite presence. Human objects detection, behavior recognition and prediction in smart surveillance fall into that category, where a transition of a huge volume of video streaming data can take valuable time and place heavy pressure on communication networks. It is widely recognized that video processing and object detection are computing intensive and too expensive to be handled by resource-limited edge devices. Inspired by the depthwise separable convolution and Single Shot Multi-Box Detector (SSD), a lightweight Convolutional Neural Network (L-CNN) is introduced in this paper. By narrowing down the classifier's searching space to focus on human objects in surveillance video frames, the proposed L-CNN algorithm is able to detect pedestrians with an affordable computation workload to an edge device. A prototype has been implemented on an edge node (Raspberry PI 3) using openCV libraries, and satisfactory performance is achieved using real-world surveillance video streams. The experimental study has validated the design of L-CNN and shown it is a promising approach to computing intensive applications at the edge.},
archivePrefix = {arXiv},
arxivId = {1805.00330},
author = {Nikouei, Seyed Yahya and Chen, Yu and Song, Sejun and Xu, Ronghua and Choi, Baek Young and Faughnan, Timothy R.},
booktitle = {Proceedings - 2018 IEEE International Conference on Edge Computing, EDGE 2018 - Part of the 2018 IEEE World Congress on Services},
doi = {10.1109/EDGE.2018.00025},
eprint = {1805.00330},
isbn = {9781538672389},
keywords = {Edge Computing,Human Objects Detection,Lightweight Convolutional Neural Network (L-CNN),Smart Surveillance},
title = {{Real-time human detection as an edge service enabled by a lightweight CNN}},
year = {2018}
}
@article{LeiteRibeiroPedro2017,
abstract = {<div class="page" title="Page 1"><div class="layoutArea"><div class="column"><p><span>A partir do campo da Ci{\^{e}}ncia, Tecnologia e Sociedade (CTS) e dos fundamentos da Teoria Ator-Rede (TAR), o presente artigo busca abordar a associa{\c{c}}{\~{a}}o entre videomonitoramento, produ{\c{c}}{\~{a}}o de seguran{\c{c}}a e pol{\'{i}}ticas p{\'{u}}blicas, mediante a descri{\c{c}}{\~{a}}o de pr{\'{a}}ticas contempor{\^{a}}neas de vigil{\^{a}}ncia articuladas aos processos de constru{\c{c}}{\~{a}}o de redes sociot{\'{e}}cnicas. Parte-se das publica{\c{c}}{\~{o}}es de estudos sobre videovigil{\^{a}}ncia realizados no Rio de Janeiro, Chapec{\'{o}} e Bruxelas, com o objetivo de apresentar e discutir algumas experi{\^{e}}ncias da instala{\c{c}}{\~{a}}o de c{\^{a}}meras de videomonitoramento, com foco em temas controversos. A cartografia das controv{\'{e}}rsias realizada permite identificar as singularidades bem como os aspectos comuns entre as experi{\^{e}}ncias nos diferentes espa{\c{c}}os urbanos abrangidos, as quais possibilitam levantar quest{\~{o}}es que contribuem para a discuss{\~{a}}o sobre o videomonitoramento e pol{\'{i}}ticas p{\'{u}}blicas contempor{\^{a}}neas de seguran{\c{c}}a, assim como seus efeitos de subjetividade e sociabilidade. </span></p></div></div></div>},
author = {{Leite Ribeiro Pedro}, Rosa Maria and {Salete Bonamigo}, Irme and Melga{\c{c}}o, Lucas},
doi = {10.29146/eco-pos.v20i3.14475},
issn = {0104-6160},
journal = {Revista ECO-P{\'{o}}s},
title = {{Videomonitoramento e seus efeitos na cidade: cartografia de redes sociot{\'{e}}cnicas em diferentes espa{\c{c}}os urbanos}},
}
@article{Cerqueira2007,
abstract = {O crescimento da viol{\^{e}}ncia no Brasil, principalmente nos grandes centros urbanos, tem gerado uma enorme discuss{\~{a}}o acerca de quais seriam as conseq{\"{u}}{\^{e}}ncias e os custos da{\'{i}} originados. Tal discuss{\~{a}}o {\'{e}} de fundamental import{\^{a}}ncia, posto que os c{\'{a}}lculos associados podem vir a orientar corretamente a aloca{\c{c}}{\~{a}}o de recursos p{\'{u}}blicos para determinados programas que visem a diminui{\c{c}}{\~{a}}o desses incidentes, com base nos princ{\'{i}}pios da efic{\'{a}}cia e efici{\^{e}}ncia, que pressup{\~{o}}em o conhecimento de rela{\c{c}}{\~{o}}es custos e benef{\'{i}}cios envolvidos. Contudo, tal discuss{\~{a}}o esbarra normalmente em duas quest{\~{o}}es: i) na enorme variedade de defini{\c{c}}{\~{o}}es e n{\~{a}}o concord{\^{a}}ncia de quais seriam esses custos; e ii) na dificuldade metodol{\'{o}}gica para a obten{\c{c}}{\~{a}}o desses c{\'{a}}lculos, aliada {\`{a}} precariedade e inexist{\^{e}}ncia de dados. Neste texto, al{\'{e}}m de apresentarmos estimativas dos custos da viol{\^{e}}ncia, in{\'{e}}ditas para o Brasil, fornecemos uma descri{\c{c}}{\~{a}}o dos usos da an{\'{a}}lise econ{\^{o}}mica do custo-benef{\'{i}}cio e do custo-efic{\'{a}}cia aplicados {\`{a}}s pol{\'{i}}ticas de preven{\c{c}}{\~{a}}o {\`{a}} viol{\^{e}}ncia, bem como discutimos sucintamente as metodologias dispon{\'{i}}veis para o seu c{\'{a}}lculo. Estimamos que em 2004, o custo da viol{\^{e}}ncia no Brasil foi de R$ 92,2 bilh{\~{o}}es, o que representou 5,09% do PIB, ou um valor per capita de R$ 519,40. Deste total, R$ 28,7 bilh{\~{o}}es corresponderam a despesas efetuadas pelo setor p{\'{u}}blico e R$ 60,3 bilh{\~{o}}es foram associados aos custos tang{\'{i}}veis e intang{\'{i}}veis arcados pelo setor privado.},
author = {Cerqueira, Daniel R C and Carvalho, Alexandre X. Y. and Lob{\~{a}}o, Waldir J. a. and Rodrigues, Rute I.},
journal = {Texto Para Discuss{\~{a}}o},
title = {{AN{\'{A}}LISE DOS CUSTOS e Consequencias da viol{\^{e}}ncia no Brasil}},
year = {2007}
}
@inproceedings{RamosLima2019,
author = {{Ramos Lima}, Gustavo and {Marques Ciarelli}, Patrick},
doi = {10.17648/sbai-2019-111276},
title = {{Sistema de Videomonitoramento com Identifica{\c{c}}{\~{a}}o de Suspeitos Utilizando Biometria Facial}},
year = {2019}
}
@inproceedings{Aazam2014,
abstract = {With the increasing applications in the domains of ubiquitous and context-aware computing, Internet of Things (IoT) are gaining importance. In IoTs, literally anything can be part of it, whether it is sensor nodes or dumb objects, so very diverse types of services can be produced. In this regard, resource management, service creation, service management, service discovery, data storage, and power management would require much better infrastructure and sophisticated mechanism. The amount of data IoTs are going to generate would not be possible for standalone power-constrained IoTs to handle. Cloud computing comes into play here. Integration of IoTs with cloud computing, termed as Cloud of Things (CoT) can help achieve the goals of envisioned IoT and future Internet. This IoT-Cloud computing integration is not straight-forward. It involves many challenges. One of those challenges is data trimming. Because unnecessary communication not only burdens the core network, but also the data center in the cloud. For this purpose, data can be preprocessed and trimmed before sending to the cloud. This can be done through a Smart Gateway, accompanied with a Smart Network or Fog Computing. In this paper, we have discussed this concept in detail and present the architecture of Smart Gateway with Fog Computing. We have tested this concept on the basis of Upload Delay, Synchronization Delay, Jitter, Bulk-data Upload Delay, and Bulk-data Synchronization Delay.},
author = {Aazam, Mohammad and Huh, Eui Nam},
booktitle = {Proceedings - 2014 International Conference on Future Internet of Things and Cloud, FiCloud 2014},
doi = {10.1109/FiCloud.2014.83},
isbn = {9781479943586},
keywords = {CoT,IoT,cloud computing,fog computing,smart gateway},
title = {{Fog computing and smart gateway based communication for cloud of things}},
year = {2014}
}
@article{Merenda2020,
abstract = {In a few years, the world will be populated by billions of connected devices that will be placed in our homes, cities, vehicles, and industries. Devices with limited resources will interact with the surrounding environment and users. Many of these devices will be based on machine learning models to decode meaning and behavior behind sensors' data, to implement accurate predictions and make decisions. The bottleneck will be the high level of connected things that could congest the network. Hence, the need to incorporate intelligence on end devices using machine learning algorithms. Deploying machine learning on such edge devices improves the network ongestion by allowing computations to be performed close to the data sources. The aim of this work is to provide a review of the main techniques that guarantee the execution of machine learning models on hardware with low performances in the Internet of Things paradigm, paving the way to the Internet of Conscious Things. In this work, a detailed review on models, architecture, and requirements on solutions that implement edge machine learning on Internet of Things devices is presented, with the main goal to define the state of the art and envisioning development requirements. Furthermore, an example of edge machine learning implementation on a microcontroller will be provided, commonly regarded as the machine learning “Hello World”.},
author = {Merenda, Massimo and Porcaro, Carlo and Iero, Demetrio},
doi = {10.3390/s20092533},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Artificial intelligence,Deep learning,Edge devices,Internet of Things,Machine learning},
pmid = {32365645},
title = {{Edge machine learning for ai-enabled iot devices: A review}},
year = {2020}
}
@ARTICLE{Bellavista2013,
author={P. {Bellavista} and G. {Cardone} and A. {Corradi} and L. {Foschini}},
journal={IEEE Sensors Journal}, 
title={Convergence of MANET and WSN in IoT Urban Scenarios}, 
year={2013},
volume={13},
number={10},
pages={3558-3567},
doi={10.1109/JSEN.2013.2272099}}
@article{Atzori2010,
  title={The internet of things: A survey},
  author={Atzori, Luigi and Iera, Antonio and Morabito, Giacomo},
  journal={Computer networks},
  volume={54},
  number={15},
  pages={2787--2805},
  year={2010},
  publisher={Elsevier}
}
@article{Szeliski2011,
abstract = {As humans, we perceive the three-dimensional structure of the world around us with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem, and what is the current state of the art?Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging and fun consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos.More than just a source of "recipes", this text/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting this process to produce the best possible descriptions of a scene. Exercises are presented throughout the book, with a heavy emphasis on testing algorithms.Suitable for either an undergraduate or a graduate-level course in computer vision, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries.Dr. Richard Szeliski has over twenty years' experience in computer vision research, most notably at Digital Equipment Corporation and Microsoft.},
author = {Szeliski, Richard},
doi = {10.5860/choice.48-5140},
issn = {0009-4978},
journal = {Choice Reviews Online},
title = {{Computer vision: algorithms and applications}},
year = {2011}
}
@book{Aggarwal2018,
abstract = {This book covers both classical and modern models in deep learning. The primary focus is on the theory and algorithms of deep learning. The theory and algorithms of neural networks are particularly important for understanding important concepts, so that one can understand the important design concepts of neural architectures in different applications. Why do neural networks work? When do they work better than off-the-shelf machine-learning models? When is depth useful? Why is training neural networks so hard? What are the pitfalls? The book is also rich in discussing different applications in order to give the practitioner a flavor of how neural architectures are designed for different types of problems. Applications associated with many different areas like recommender systems, machine translation, image captioning, image classification, reinforcement-learning based gaming, and text analytics are covered. The chapters of this book span three categories: The basics of neural networks: Many traditional machine learning models can be understood as special cases of neural networks. An emphasis is placed in the first two chapters on understanding the relationship between traditional machine learning and neural networks. Support vector machines, linear/logistic regression, singular value decomposition, matrix factorization, and recommender systems are shown to be special cases of neural networks. These methods are studied together with recent feature engineering methods like word2vec. Fundamentals of neural networks: A detailed discussion of training and regularization is provided in Chapters 3 and 4. Chapters 5 and 6 present radial-basis function (RBF) networks and restricted Boltzmann machines. Advanced topics in neural networks: Chapters 7 and 8 discuss recurrent neural networks and convolutional neural networks. Several advanced topics like deep reinforcement learning, neural Turing machines, Kohonen self-organizing maps, and generative adversarial networks are introduced in Chapters 9 and 10. The book is written for graduate students, researchers, and practitioners. Numerous exercises are available along with a solution manual to aid in classroom teaching. Where possible, an application-centric view is highlighted in order to provide an understanding of the practical uses of each class of techniques.},
author = {Aggarwal, Charu C.},
booktitle = {Neural Networks and Deep Learning},
doi = {10.1007/978-3-319-94463-0},
title = {{Neural Networks and Deep Learning}},
year = {2018}
}
@inproceedings{Singh2017,
  title={Optimize cloud computations using edge computing},
  author={Singh, Sachchidanand},
  booktitle={2017 International Conference on Big Data, IoT and Data Science (BID)},
  pages={49--53},
  year={2017},
  organization={IEEE}
}
@inproceedings{Dolui2017,
abstract = {When it comes to storage and computation of large scales of data, Cloud Computing has acted as the de-facto solution over the past decade. However, with the massive growth in intelligent and mobile devices coupled with technologies like Internet of Things (IoT), V2X Communications, Augmented Reality (AR), the focus has shifted towards gaining real-time responses along with support for context-awareness and mobility. Due to the delays induced on the Wide Area Network (WAN) and location agnostic provisioning of resources on the cloud, there is a need to bring the features of the cloud closer to the consumer devices. This led to the birth of the Edge Computing paradigm which aims to provide context aware storage and distributed Computing at the edge of the networks. In this paper, we discuss the three different implementations of Edge Computing namely Fog Computing, Cloudlet and Mobile Edge Computing in detail and compare their features. We define a set of parameters based on which one of these implementations can be chosen optimally given a particular use-case or application and present a decision tree for the selection of the optimal implementation.},
author = {Dolui, Koustabh and Datta, Soumya Kanti},
booktitle = {GIoTS 2017 - Global Internet of Things Summit, Proceedings},
doi = {10.1109/GIOTS.2017.8016213},
isbn = {9781509058730},
keywords = {Cloud Computing,Cloudlet,Edge Computing,Fog Computing,IoT,Mobile Edge Computing},
title = {{Comparison of edge computing implementations: Fog computing, cloudlet and mobile edge computing}},
year = {2017}
}
@book{Song2017,
abstract = {Provides the foundations and principles needed for addressing the various challenges of developing smart cities. Smart cities are emerging as a priority for research and development across the world. They open up significant opportunities in several areas, such as economic growth, health, wellness, energy efficiency, and transportation, to promote the sustainable development of cities. This book provides the basics of smart cities, and it examines the possible future trends of this technology. Smart Cities: Foundations, Principles, and Applications provides a systems science perspective in presenting the foundations and principles that span multiple disciplines for the development of smart cities. Divided into three parts-foundations, principles, and applications-Smart Cities addresses the various challenges and opportunities of creating smart cities and all that they have to offer. It also covers smart city theory modeling and simulation, and examines case studies of existing smart cities from all around the world. In addition, the book: Addresses how to develop a smart city and how to present the state of the art and practice of them all over the world; Focuses on the foundations and principles needed for advancing the science, engineering, and technology of smart cities-including system design, system verification, real-time control and adaptation, Internet of Things, and test beds; Covers applications of smart cities as they relate to smart transportation/connected vehicle (CV) and Intelligent Transportation Systems (ITS) for improved mobility, safety, and environmental protection; Smart Cities: Foundations, Principles, and Applications is a welcome reference for the many researchers and professionals working on the development of smart cities and smart city-related industries.},
author = {Song, Houbing and Srinivasan, Ravi S. and Sookoor, Tamim and Jeschke, Sabina},
booktitle = {Smart Cities: Foundations, Principles, and Applications},
doi = {10.1002/9781119226444},
isbn = {9781119226444},
title = {{Smart Cities: Foundations, Principles, and Applications}},
year = {2017}
}
@article{Verhelst2017,
abstract = {Deep learning has recently become im-mensely popular for image recognition, as well as for other recognition and pattern matching tasks in, e.g., speech processing, natural language processing, and so forth. The online evaluation of deep neural networks, however, comes with significant computational complexity, making it, until recently, feasible only on power-hungry server platforms in the cloud. In recent years, we see an emerging trend toward embedded processing of deep learning networks in edge devices: mobiles, wearables, and Internet of Things (IoT) nodes. This would enable us to analyze data locally in real time, which is not only favorable in terms of latency but also mitigates privacy issues. Yet evaluating the powerful but large deep neural networks with power budgets in the milliwatt or even microwatt range requires a significant improvement in processing energy efficiency.},
author = {Verhelst, Marian and Moons, Bert},
doi = {10.1109/MSSC.2017.2745818},
issn = {19430582},
journal = {IEEE Solid-State Circuits Magazine},
title = {{Embedded Deep Neural Network Processing: Algorithmic and Processor Techniques Bring Deep Learning to IoT and Edge Devices}},
year = {2017}
}
@unpublished{QUIRITA2014,
address = {Rio de Janeiro},
author = {QUIRITA, VICTOR HUGO AYMA},
institution = {PONTIF{\'{I}}CIA UNIVERSIDADE CAT{\'{O}}LICA DO RIO DE JANEIRO - PUC-RIO},
title = {{ESTUDO DE M{\'{E}}TODOS AUTOM{\'{A}}TICOS DE RECONHECIMENTO FACIAL PARA V{\'{I}}DEO MONITORAMENTO}},
year = {2014}
}
@inproceedings{Pacheco2018,
abstract = {The biggest growth rate of network traffic in the coming years will be for smartphones and Internet-connected devices, which relentless tend to perform increasingly demanding tasks on continuously increasing amounts of data. Machine Learning and Edge Computing are emerging as effective paradigms for processing huge amounts of data supplied by the Internet of Things and Smart Cities. An osmotic computing architecture for an IoT smart classroom is used for testing a deep learning model for person recognition. A comparative performance study and analysis was made by means of selecting a single deep learning model, that it was tried to be adapted to run over the cloud, a fog microserver and a mobile edge computing device. The results obtained shown some promising results and also limitations for the edge and fog computing side that will need to be addressed in order to minimize latencies and achieve real-time responses for the present IoT application.},
author = {Pacheco, Alberto and Cano, Pablo and Flores, Ever and Trujillo, Edgar and Marquez, Pedro},
booktitle = {2018 Congreso Internacional de Innovacion y Tendencias en Ingenieria, CONIITI 2018 - Proceedings},
doi = {10.1109/CONIITI.2018.8587095},
isbn = {9781538681312},
keywords = {Cloud Computing,Deep Learning,Internet of Things,Mobile Edge Computing,Smart Buildings,Smart Living},
title = {{A Smart Classroom Based on Deep Learning and Osmotic IoT Computing}},
year = {2018}
}

